/**
 * Script de Otimiza√ß√£o do Banco de Dados PostgreSQL
 * Fase 3 - Otimiza√ß√µes Avan√ßadas
 */

const { Pool } = require('pg');
const fs = require('fs');
const path = require('path');

// Configura√ß√£o do banco
const pool = new Pool({
  host: process.env.POSTGRES_HOST || 'localhost',
  port: parseInt(process.env.POSTGRES_PORT || '5432'),
  database: process.env.POSTGRES_DB || 'erp_pizzaria',
  user: process.env.POSTGRES_USER || 'postgres',
  password: process.env.POSTGRES_PASSWORD || '134679',
  ssl: false
});

// √çndices otimizados para performance
const optimizedIndexes = [
  {
    name: 'idx_profiles_email_active',
    table: 'profiles',
    columns: ['email', 'active'],
    type: 'btree',
    reason: 'Otimizar login e busca de usu√°rios ativos'
  },
  {
    name: 'idx_profiles_role_active',
    table: 'profiles',
    columns: ['role', 'active'],
    type: 'btree',
    reason: 'Otimizar busca de usu√°rios por role'
  },
  {
    name: 'idx_products_category_active',
    table: 'products',
    columns: ['category_id', 'active'],
    type: 'btree',
    reason: 'Otimizar listagem de produtos por categoria'
  },
  {
    name: 'idx_products_name_search',
    table: 'products',
    columns: ['name'],
    type: 'gin',
    reason: 'Otimizar busca textual de produtos',
    special: true
  },
  {
    name: 'idx_products_price_active',
    table: 'products',
    columns: ['price', 'active'],
    type: 'btree',
    reason: 'Otimizar filtros por faixa de pre√ßo'
  },
  {
    name: 'idx_orders_customer_status',
    table: 'orders',
    columns: ['customer_id', 'status'],
    type: 'btree',
    reason: 'Otimizar consulta de pedidos por cliente e status'
  },
  {
    name: 'idx_orders_created_at_desc',
    table: 'orders',
    columns: ['created_at DESC'],
    type: 'btree',
    reason: 'Otimizar ordena√ß√£o por data de cria√ß√£o (mais recentes primeiro)'
  },
  {
    name: 'idx_orders_status_created',
    table: 'orders',
    columns: ['status', 'created_at'],
    type: 'btree',
    reason: 'Otimizar dashboard admin por status e data'
  },
  {
    name: 'idx_order_items_order_id',
    table: 'order_items',
    columns: ['order_id'],
    type: 'btree',
    reason: 'Otimizar busca de itens por pedido'
  },
  {
    name: 'idx_order_items_product_stats',
    table: 'order_items',
    columns: ['product_id', 'created_at'],
    type: 'btree',
    reason: 'Otimizar relat√≥rios de produtos mais vendidos'
  },
  {
    name: 'idx_favorites_customer_product',
    table: 'favorites',
    columns: ['customer_id', 'product_id'],
    type: 'btree',
    reason: 'Otimizar verifica√ß√£o de favoritos (unique constraint)'
  },
  {
    name: 'idx_customer_addresses_customer_active',
    table: 'customer_addresses',
    columns: ['customer_id', 'active'],
    type: 'btree',
    reason: 'Otimizar busca de endere√ßos ativos por cliente'
  },
  {
    name: 'idx_refresh_tokens_token_hash',
    table: 'refresh_tokens',
    columns: ['token'],
    type: 'hash',
    reason: 'Otimizar valida√ß√£o de refresh tokens'
  },
  {
    name: 'idx_refresh_tokens_user_expires',
    table: 'refresh_tokens',
    columns: ['user_id', 'expires_at'],
    type: 'btree',
    reason: 'Otimizar limpeza de tokens expirados'
  },
  {
    name: 'idx_categories_active_sort',
    table: 'categories',
    columns: ['active', 'sort_order'],
    type: 'btree',
    reason: 'Otimizar listagem ordenada de categorias ativas'
  }
];

// Configura√ß√µes de otimiza√ß√£o do PostgreSQL
const postgresOptimizations = [
  {
    setting: 'work_mem',
    value: '16MB',
    description: 'Mem√≥ria para opera√ß√µes de ordena√ß√£o e hash'
  },
  {
    setting: 'shared_buffers',
    value: '256MB',
    description: 'Buffer compartilhado (25% da RAM)'
  },
  {
    setting: 'effective_cache_size',
    value: '1GB',
    description: 'Tamanho estimado do cache do SO (75% da RAM)'
  },
  {
    setting: 'random_page_cost',
    value: '1.1',
    description: 'Custo de p√°gina aleat√≥ria (otimizado para SSD)'
  },
  {
    setting: 'checkpoint_completion_target',
    value: '0.9',
    description: 'Target para conclus√£o de checkpoint'
  },
  {
    setting: 'wal_buffers',
    value: '16MB',
    description: 'Buffers do WAL'
  },
  {
    setting: 'default_statistics_target',
    value: '100',
    description: 'Target de estat√≠sticas para otimizador'
  }
];

async function main() {
  console.log('üöÄ Iniciando otimiza√ß√£o do banco de dados PostgreSQL...');
  
  try {
    // Conectar ao banco
    await pool.query('SELECT NOW()');
    console.log('‚úÖ Conex√£o com PostgreSQL estabelecida');
    
    // 1. Analisar estado atual
    console.log('\nüìä Analisando estado atual do banco...');
    await analyzeCurrentState();
    
    // 2. Criar √≠ndices otimizados
    console.log('\nüîß Criando √≠ndices otimizados...');
    await createOptimizedIndexes();
    
    // 3. Aplicar configura√ß√µes de otimiza√ß√£o
    console.log('\n‚öôÔ∏è Aplicando configura√ß√µes de otimiza√ß√£o...');
    await applyOptimizations();
    
    // 4. Executar manuten√ß√£o das tabelas
    console.log('\nüßπ Executando manuten√ß√£o das tabelas...');
    await maintainTables();
    
    // 5. Analisar performance ap√≥s otimiza√ß√µes
    console.log('\nüìà Analisando performance ap√≥s otimiza√ß√µes...');
    await analyzePerformance();
    
    // 6. Gerar relat√≥rio
    console.log('\nüìã Gerando relat√≥rio de otimiza√ß√£o...');
    await generateOptimizationReport();
    
    console.log('\nüéâ Otimiza√ß√£o conclu√≠da com sucesso!');
    
  } catch (error) {
    console.error('‚ùå Erro durante otimiza√ß√£o:', error);
    process.exit(1);
  } finally {
    await pool.end();
  }
}

async function analyzeCurrentState() {
  try {
    // Verificar tamanho do banco
    const sizeResult = await pool.query(`
      SELECT pg_size_pretty(pg_database_size(current_database())) as database_size
    `);
    console.log(`   Tamanho do banco: ${sizeResult.rows[0].database_size}`);
    
    // Verificar √≠ndices existentes
    const indexesResult = await pool.query(`
      SELECT 
        schemaname,
        tablename,
        indexname,
        pg_size_pretty(pg_relation_size(indexrelid)) as size
      FROM pg_stat_user_indexes 
      ORDER BY pg_relation_size(indexrelid) DESC
      LIMIT 10
    `);
    
    console.log('   √çndices existentes (top 10 por tamanho):');
    indexesResult.rows.forEach(row => {
      console.log(`     ${row.tablename}.${row.indexname}: ${row.size}`);
    });
    
    // Verificar estat√≠sticas de tabelas
    const tablesResult = await pool.query(`
      SELECT 
        tablename,
        n_live_tup as live_rows,
        n_dead_tup as dead_rows,
        pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
      FROM pg_stat_user_tables 
      ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
    `);
    
    console.log('   Estat√≠sticas das tabelas:');
    tablesResult.rows.forEach(row => {
      console.log(`     ${row.tablename}: ${row.live_rows} linhas vivas, ${row.dead_rows} mortas, ${row.size}`);
    });
    
  } catch (error) {
    console.error('   Erro ao analisar estado atual:', error.message);
  }
}

async function createOptimizedIndexes() {
  let createdCount = 0;
  let skippedCount = 0;
  
  for (const index of optimizedIndexes) {
    try {
      // Verificar se √≠ndice j√° existe
      const existsResult = await pool.query(
        'SELECT 1 FROM pg_indexes WHERE indexname = $1',
        [index.name]
      );
      
      if (existsResult.rows.length > 0) {
        console.log(`   ‚è≠Ô∏è  √çndice ${index.name} j√° existe`);
        skippedCount++;
        continue;
      }
      
      // Criar √≠ndice
      let createQuery = '';
      
      if (index.special && index.type === 'gin') {
        // √çndice GIN para busca textual
        createQuery = `CREATE INDEX ${index.name} ON ${index.table} USING gin(to_tsvector('portuguese', ${index.columns[0]}))`;
      } else {
        const columnsStr = index.columns.join(', ');
        createQuery = `CREATE INDEX ${index.name} ON ${index.table} USING ${index.type} (${columnsStr})`;
      }
      
      await pool.query(createQuery);
      console.log(`   ‚úÖ Criado: ${index.name} (${index.reason})`);
      createdCount++;
      
    } catch (error) {
      console.error(`   ‚ùå Erro ao criar ${index.name}:`, error.message);
    }
  }
  
  console.log(`   üìä Resumo: ${createdCount} criados, ${skippedCount} j√° existiam`);
}

async function applyOptimizations() {
  let appliedCount = 0;
  
  for (const optimization of postgresOptimizations) {
    try {
      const query = `SET ${optimization.setting} = '${optimization.value}'`;
      await pool.query(query);
      console.log(`   ‚úÖ ${optimization.setting} = ${optimization.value} (${optimization.description})`);
      appliedCount++;
    } catch (error) {
      console.error(`   ‚ùå Erro ao aplicar ${optimization.setting}:`, error.message);
    }
  }
  
  console.log(`   üìä ${appliedCount}/${postgresOptimizations.length} configura√ß√µes aplicadas`);
}

async function maintainTables() {
  const tables = ['profiles', 'categories', 'products', 'orders', 'order_items', 'favorites', 'customer_addresses', 'refresh_tokens'];
  
  for (const table of tables) {
    try {
      console.log(`   üßπ Mantendo tabela ${table}...`);
      
      // VACUUM para recuperar espa√ßo
      await pool.query(`VACUUM ${table}`);
      
      // ANALYZE para atualizar estat√≠sticas
      await pool.query(`ANALYZE ${table}`);
      
      console.log(`   ‚úÖ ${table} mantida`);
    } catch (error) {
      console.error(`   ‚ùå Erro ao manter ${table}:`, error.message);
    }
  }
}

async function analyzePerformance() {
  try {
    // Cache hit ratio
    const cacheResult = await pool.query(`
      SELECT 
        sum(blks_hit) as hits,
        sum(blks_read) as reads,
        round(sum(blks_hit) * 100.0 / (sum(blks_hit) + sum(blks_read)), 2) as hit_ratio
      FROM pg_stat_database
    `);
    
    const hitRatio = cacheResult.rows[0].hit_ratio || 0;
    console.log(`   üìä Cache hit ratio: ${hitRatio}%`);
    
    // √çndices mais utilizados
    const indexUsageResult = await pool.query(`
      SELECT 
        schemaname,
        tablename,
        indexname,
        idx_tup_read + idx_tup_fetch as total_reads
      FROM pg_stat_user_indexes 
      WHERE idx_tup_read + idx_tup_fetch > 0
      ORDER BY total_reads DESC
      LIMIT 5
    `);
    
    console.log('   üîù √çndices mais utilizados:');
    indexUsageResult.rows.forEach(row => {
      console.log(`     ${row.tablename}.${row.indexname}: ${row.total_reads} leituras`);
    });
    
    // Queries mais lentas (se dispon√≠vel)
    try {
      const slowQueriesResult = await pool.query(`
        SELECT 
          query,
          calls,
          total_time,
          mean_time,
          rows
        FROM pg_stat_statements 
        WHERE mean_time > 100
        ORDER BY mean_time DESC
        LIMIT 5
      `);
      
      if (slowQueriesResult.rows.length > 0) {
        console.log('   üêå Queries mais lentas (>100ms):');
        slowQueriesResult.rows.forEach(row => {
          console.log(`     ${row.mean_time.toFixed(2)}ms: ${row.query.substring(0, 60)}...`);
        });
      }
    } catch (error) {
      console.log('   ‚ÑπÔ∏è  pg_stat_statements n√£o dispon√≠vel para an√°lise de queries');
    }
    
  } catch (error) {
    console.error('   ‚ùå Erro ao analisar performance:', error.message);
  }
}

async function generateOptimizationReport() {
  const timestamp = new Date().toISOString();
  const reportPath = path.join(__dirname, '..', 'reports', `database-optimization-${timestamp.split('T')[0]}.md`);
  
  // Criar diret√≥rio de relat√≥rios se n√£o existir
  const reportsDir = path.dirname(reportPath);
  if (!fs.existsSync(reportsDir)) {
    fs.mkdirSync(reportsDir, { recursive: true });
  }
  
  const report = `# Relat√≥rio de Otimiza√ß√£o do Banco de Dados

**Data:** ${timestamp}
**Banco:** erp_pizzaria

## √çndices Criados

${optimizedIndexes.map(index => 
  `- **${index.name}** (${index.table}): ${index.reason}`
).join('\n')}

## Configura√ß√µes Aplicadas

${postgresOptimizations.map(opt => 
  `- **${opt.setting}**: ${opt.value} - ${opt.description}`
).join('\n')}

## Pr√≥ximos Passos

1. Monitorar performance das queries ap√≥s otimiza√ß√µes
2. Executar VACUUM FULL se necess√°rio (em hor√°rio de baixo uso)
3. Considerar particionamento para tabelas grandes
4. Implementar monitoramento cont√≠nuo de performance

## Comandos √öteis

\`\`\`sql
-- Verificar uso de √≠ndices
SELECT * FROM pg_stat_user_indexes ORDER BY idx_tup_read + idx_tup_fetch DESC;

-- Verificar cache hit ratio
SELECT 
  sum(blks_hit) * 100.0 / (sum(blks_hit) + sum(blks_read)) as hit_ratio
FROM pg_stat_database;

-- Verificar queries lentas (se pg_stat_statements estiver habilitado)
SELECT query, mean_time, calls FROM pg_stat_statements ORDER BY mean_time DESC LIMIT 10;
\`\`\`
`;
  
  try {
    fs.writeFileSync(reportPath, report);
    console.log(`   üìÑ Relat√≥rio salvo em: ${reportPath}`);
  } catch (error) {
    console.error('   ‚ùå Erro ao salvar relat√≥rio:', error.message);
  }
}

// Executar se chamado diretamente
if (require.main === module) {
  main();
}

module.exports = {
  createOptimizedIndexes,
  applyOptimizations,
  maintainTables,
  analyzePerformance
};